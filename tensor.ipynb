{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad2d52e",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28016ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b618f31",
   "metadata": {},
   "source": [
    "## 1 Creating Tensor\n",
    "PyTorch needs an appropriate data format in the form of tensor. This means that our data must be loaded into tensors. \n",
    "\n",
    "### 1.1 Creating Tensor from Existing Data Structure\n",
    "Often our data will be in a common format like a python list, a NumPy array, or pandas DataFrame. We can convert those data with pytorch using `torch.tensor()`.\n",
    "\n",
    "**Python list to Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893aee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python list \n",
    "py_list = [1, 2, 3]\n",
    "\n",
    "# Convert the python list into tensor\n",
    "py_tensor = torch.tensor(py_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e61d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb9973d",
   "metadata": {},
   "source": [
    "**Numpy Array to Pytorch Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793a45b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Torch tensor from numpy\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "\n",
    "print(\"Numpy array:\")\n",
    "print(numpy_array)\n",
    "\n",
    "print(\"\\nTorch tensor from numpy\")\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be58e89",
   "metadata": {},
   "source": [
    "**From Pandas DataFrame**\n",
    "\n",
    "DataFrame is pandas' main ds for storing tabular data. DataFrames are one of the most common ways to load and explore dataset in ML, especially when reading CSV file. But there is no direct function to convert a DataFrame to a tensor. The standard method is to extract the data from the DataFrame into a NumPy array using the `.values` attribute, and then convert that array into tensor using `torch.tensor()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2590865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_miles</th>\n",
       "      <th>delivery_time_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.60</td>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.09</td>\n",
       "      <td>32.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.97</td>\n",
       "      <td>17.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_miles  delivery_time_minutes\n",
       "0            1.60                   7.22\n",
       "1           13.09                  32.41\n",
       "2            6.97                  17.47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/data.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26526a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6 ,  7.22],\n",
       "       [13.09, 32.41],\n",
       "       [ 6.97, 17.47]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the data as numpy array from the dataframe\n",
    "all_values = df.values\n",
    "all_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b16c285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DATAFRAME:\n",
      "\n",
      "    distance_miles  delivery_time_minutes\n",
      "0            1.60                   7.22\n",
      "1           13.09                  32.41\n",
      "2            6.97                  17.47\n",
      "\n",
      "RESULTING TENSOR:\n",
      "\n",
      " tensor([[ 1.6000,  7.2200],\n",
      "        [13.0900, 32.4100],\n",
      "        [ 6.9700, 17.4700]], dtype=torch.float64)\n",
      "\n",
      "TENSOR DATA TYPE: torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Convert the DF values to a PyTorch tensor\n",
    "tensor_from_pandas = torch.tensor(all_values)\n",
    "\n",
    "print(\"ORIGINAL DATAFRAME:\\n\\n\", df)\n",
    "print(\"\\nRESULTING TENSOR:\\n\\n\", tensor_from_pandas)\n",
    "print(\"\\nTENSOR DATA TYPE:\", tensor_from_pandas.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9283a",
   "metadata": {},
   "source": [
    "### 1.2 Creating Tensor from Predefined Values\n",
    "Sometimes, when we need to create tensors for specific purposes, for example initializing a model's weights and biases before training begins. We can use PyTorch to quickly generate tensors filled with placeholder values like zeroes, ones, or random numbers which is useful for testing and setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef74d0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All zeroes\n",
    "zeros = torch.zeros(2, 3)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe97ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2080, 0.6147, 0.9823],\n",
       "        [0.2405, 0.1865, 0.2530]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random = torch.rand(2, 3)\n",
    "random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ec4a8",
   "metadata": {},
   "source": [
    "### 1.3 Creating Tensor from a Sequence\n",
    "If we want to generate sequence of data points, such as range of values for testing model's predictions, we can create tensor directly from seq. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f36f64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.5000, 3.0000, 4.5000, 6.0000, 7.5000, 9.0000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_tensor = torch.arange(0, 10, step=1.5)\n",
    "range_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da394c8",
   "metadata": {},
   "source": [
    "## 2. Reshaping and Manipulating\n",
    "A mismatch between the shape of data and the shape that the model expects is a common source of error in PyTorch. \n",
    "\n",
    "### 2.1  Checking a Tensor's Dimensions\n",
    "Understanding tensor's dimension is the first step to fixing a shape mismatch. This tells us how many samples we have and how many featues in each sample. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93b0d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# A 2D tensor\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288d99b",
   "metadata": {},
   "source": [
    "### 2.2 Changing Tensor's Dimension\n",
    "When we identify tensor's shape mismatch, we need to correct it. A frequent task is adding a dimension to a single data sample to create a batch of size one for our model, or removing a dimension after a batch operation is complete.\n",
    "\n",
    "- **Adding dimension**: `torch.Tensor.unsqueeze()` inserts a new dim at specific index.\n",
    "  - Notice how the shape change from [2, 3] to [1, 2, 3] and the tensor gets wrapped in an extra pair of square brackets `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5da17e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "TENSOR WITH ADDED DIMENSION AT INDEX 0:\n",
      "\n",
      " tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "\n",
      "TENSOR SHAPE torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# add dimension\n",
    "expanded = x.unsqueeze(0) # add dimension at index 0 \n",
    "\n",
    "print(\"\\nTENSOR WITH ADDED DIMENSION AT INDEX 0:\\n\\n\", expanded)\n",
    "print(\"\\nTENSOR SHAPE\", expanded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4581c677",
   "metadata": {},
   "source": [
    "**Removing Dimension**\n",
    "We can use `torch.Tensor.squeeze()` to remove dimensions of size 1. This is the reverse of `unsqueeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e52d83b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPANDED TENSOR:\n",
      "\n",
      " tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([1, 2, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "TENSOR WITH DIMENSION REMOVED:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"EXPANDED TENSOR:\\n\\n\", expanded)\n",
    "print(\"\\nTENSOR SHAPE:\", expanded.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Remove dimension\n",
    "squeezed = expanded.squeeze()\n",
    "\n",
    "print(\"\\nTENSOR WITH DIMENSION REMOVED:\\n\\n\", squeezed)\n",
    "print(\"\\nTENSOR SHAPE:\", squeezed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab1d06",
   "metadata": {},
   "source": [
    "## 2.3 Restructuring\n",
    "Beyond just adding or removing dimensions, we may need to completely change a tensor's structure to match the requirements of a specific layer or operation within our neural network.\n",
    "\n",
    "`torch.Tensor.reshape()` changes the shape of tensor to the specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b04d7a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "AFTER PERFORMING reshape(3, 2):\n",
      "\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Reshape\n",
    "reshaped = x.reshape(3, 2)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING reshape(3, 2):\\n\\n\", reshaped)\n",
    "print(\"\\nTENSOR SHAPE:\", reshaped.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27ef6f",
   "metadata": {},
   "source": [
    "**Transposing**\n",
    "\n",
    "Swaps the specified dimensions of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff7ed55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "AFTER PERFORMING transpose(0, 1):\n",
      "\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "transposed =x.transpose(0, 1)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING transpose(0, 1):\\n\\n\", transposed)\n",
    "print(\"\\nTENSOR SHAPE:\", transposed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84908c17",
   "metadata": {},
   "source": [
    "### 2.4 Combining Tensors\n",
    "In the data preparation stage, we might need to combine data from different sources or merge separate batches into one larger dataset.\n",
    "\n",
    "`torch.cat()` joins a sequence of tensors along an existing dimension. \n",
    "\n",
    "**Note**: All tensors must have the same shape in dimensions other than the one being concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "047168d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = torch.tensor([[1, 2],\n",
    "                         [3, 4]])\n",
    "tensor_b = torch.tensor([[5, 6],\n",
    "                         [7, 8]])\n",
    "\n",
    "# Concatenate along colimns\n",
    "tensor_ab = torch.cat((tensor_a, tensor_b), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e942398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A:\n",
      "\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "TENSOR B:\n",
      "\n",
      " tensor([[5, 6],\n",
      "        [7, 8]])\n",
      "---------------------------------------------\n",
      "\n",
      "CONCATENATED TENSOR (dim=1):\n",
      "\n",
      " tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "print(\"TENSOR A:\\n\\n\", tensor_a)\n",
    "print(\"\\nTENSOR B:\\n\\n\", tensor_b)\n",
    "print(\"-\"*45)\n",
    "print(\"\\nCONCATENATED TENSOR (dim=1):\\n\\n\", tensor_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71829431",
   "metadata": {},
   "source": [
    "## 3. Indexing and Slicing\n",
    "After we have our data in a tensor, we will often need to access specific parts of it. Whether we are grabbing a single prediction to inspect its value, separating our input features from your labels, or selecting a subset of data for analysis, indexing and slicing are the tools for the job.\n",
    "\n",
    "### 3.1 Accessing Elements\n",
    "These are the fundamental techniques for getting data out of a tensor, working very similarly to how we would access elements in a standard Python list.\n",
    "\n",
    "**Standard indexing**: Accessing single elements or entire rows using integer indices (e.g., `x[0]`, `x[1, 2]`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d8251a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "INDEXING SINGLE ELEMENT AT [1, 2]: tensor(7)\n",
      "-------------------------------------------------------\n",
      "\n",
      "INDEXING ENTIRE ROW [1]: tensor([5, 6, 7, 8])\n",
      "-------------------------------------------------------\n",
      "\n",
      "INDEXING ENTIRE LAST ROW ([-1]): tensor([ 9, 10, 11, 12]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 x 4 \n",
    "x = torch.tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12]\n",
    "])\n",
    "\n",
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get a single element at row 1, column 2\n",
    "single_element_tensor = x[1, 2]\n",
    "\n",
    "print(\"\\nINDEXING SINGLE ELEMENT AT [1, 2]:\", single_element_tensor)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get the entire second row (index 1)\n",
    "second_row = x[1]\n",
    "print(\"\\nINDEXING ENTIRE ROW [1]:\", second_row)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Last row \n",
    "last_row = x[-1]\n",
    "\n",
    "print(\"\\nINDEXING ENTIRE LAST ROW ([-1]):\", last_row, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969e798",
   "metadata": {},
   "source": [
    "<!-- * **Slicing**: Extracting sub-tensors using `[start:end:step]` notation (e.g., `x[:2, ::2]`).\n",
    "    * *Note: The `end` index itself is not included in the slice.*\n",
    "* Slicing can be used to access entire columns. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44357f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "SLICING FIRST TWO ROWS ([0:2]):\n",
      "\n",
      " tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "SLICING THIRD COLUMN ([:, 2]]): tensor([ 3,  7, 11])\n",
      "-------------------------------------------------------\n",
      "\n",
      "EVERY OTHER COLUMN ([:, ::2]):\n",
      "\n",
      " tensor([[ 1,  3],\n",
      "        [ 5,  7],\n",
      "        [ 9, 11]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "LAST COLUMN ([:, -1]): tensor([ 4,  8, 12]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get the first two rows\n",
    "first2rows = x[:2]\n",
    "\n",
    "print(\"\\nSLICING FIRST TWO ROWS ([0:2]):\\n\\n\", first2rows)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "\n",
    "# Get the 3d column of all rows \n",
    "third_column = x[:, 2]\n",
    "\n",
    "print(\"\\nSLICING THIRD COLUMN ([:, 2]]):\", third_column)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "\n",
    "# Every other columns\n",
    "every_other_col = x[:, ::2]\n",
    "\n",
    "print(\"\\nEVERY OTHER COLUMN ([:, ::2]):\\n\\n\", every_other_col)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Last column\n",
    "last_col = x[:, -1]\n",
    "\n",
    "print(\"\\nLAST COLUMN ([:, -1]):\", last_col, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bce23b",
   "metadata": {},
   "source": [
    "**Combining Indexing & Slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a9685e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "FIRST TWO ROWS, LAST TWO COLS ([0:2, 2:]):\n",
      "\n",
      " tensor([[3, 4],\n",
      "        [7, 8]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Combining slicing and indexing (First two rows, last two columns)\n",
    "combined = x[:2, 2:]\n",
    "\n",
    "print(\"\\nFIRST TWO ROWS, LAST TWO COLS ([0:2, 2:]):\\n\\n\", combined, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa6bc6",
   "metadata": {},
   "source": [
    "`item()`, Extracts the value from a single-element tensor as a standard Python number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "462364ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE-ELEMENT TENSOR: tensor(7)\n",
      "---------------------------------------------\n",
      "\n",
      ".item() PYTHON NUMBER EXTRACTED: 7\n",
      "TYPE: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"SINGLE-ELEMENT TENSOR:\", single_element_tensor)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Extract the value from a single-element tensor as a standard Python number\n",
    "value = single_element_tensor.item()\n",
    "\n",
    "print(\"\\n.item() PYTHON NUMBER EXTRACTED:\", value)\n",
    "print(\"TYPE:\", type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf21e0f",
   "metadata": {},
   "source": [
    "### 3.2 Advanced Indexing\n",
    "For more complex data selection, such as filtering the dataset based on one or more conditions, we can use advanced indexing techniques.\n",
    "\n",
    "**Boolean masking**: Using a boolean tensor to select elements that meet a certain condition (e.g.,Â `x[x > 5]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33627a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "MASK (VALUES > 6):\n",
      "\n",
      " tensor([[False, False, False, False],\n",
      "        [False, False,  True,  True],\n",
      "        [ True,  True,  True,  True]]) \n",
      "\n",
      "VALUES AFTER APPLYING MASK: tensor([ 7,  8,  9, 10, 11, 12]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Boolean indexing using logical comparison\n",
    "mask = x > 6\n",
    "\n",
    "print(\"MASK (VALUES > 6):\\n\\n\", mask, \"\\n\")\n",
    "\n",
    "# Applying boolean masking\n",
    "mask_applied = x[mask]\n",
    "\n",
    "print(\"VALUES AFTER APPLYING MASK:\", mask_applied, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb8f8f",
   "metadata": {},
   "source": [
    "**Fancy Indexing**: Using a tensor of indices to select specific elements in a non-contiguous way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91e6373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "SPECIFIC ELEMENTS USING INDICES:\n",
      "\n",
      " tensor([[ 2,  3],\n",
      "        [10, 11]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get first and third third row \n",
    "row_indices = torch.tensor([0, 2])\n",
    "\n",
    "# Get second and third columns\n",
    "col_indices = torch.tensor([1, 2])\n",
    "\n",
    "# Gets values at (0,1), (0,3), (2,1), (2,3)\n",
    "get_values = x[row_indices[:, None], col_indices]\n",
    "\n",
    "print(\"\\nSPECIFIC ELEMENTS USING INDICES:\\n\\n\", get_values, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e9076",
   "metadata": {},
   "source": [
    "## 4 - Mathematical & Logical Operations\n",
    "\n",
    "At their core, neural networks are performing mathematical computations. A single neuron, for example, calculates a weighted sum of its inputs and adds a bias. PyTorch is optimized to perform these operations efficiently across entire tensors at once, which is what makes training so fast.\n",
    "\n",
    "### 4.1 - Arithmetic\n",
    "\n",
    "These operations are the foundation of how a neural network processes data. You'll see how PyTorch handles element-wise calculations and uses a powerful feature called broadcasting to simplify your code.\n",
    "\n",
    "* **Element-wise Operations**: Standard math operators (`+`, `*`) that apply to each element independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a1dde6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A: tensor([1, 2, 3])\n",
      "TENSOR B tensor([4, 5, 6])\n",
      "------------------------------------------------------------\n",
      "\n",
      "AFTER PERFORMING ELEMENT-WISE ADDITION: tensor([5, 7, 9]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B\", b)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Element-wise addition\n",
    "element_add = a + b\n",
    "\n",
    "print(\"\\nAFTER PERFORMING ELEMENT-WISE ADDITION:\", element_add, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9093f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A: tensor([1, 2, 3])\n",
      "TENSOR B tensor([4, 5, 6])\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "AFTER PERFORMING ELEMENT-WISE MULTIPLICATION: tensor([ 4, 10, 18]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B\", b)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Element-wise multiplication\n",
    "element_mul = a * b\n",
    "\n",
    "print(\"\\nAFTER PERFORMING ELEMENT-WISE MULTIPLICATION:\", element_mul, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a23b4a",
   "metadata": {},
   "source": [
    "**Dot Product** (`torch.matmul()`): Calculates the dot product of two vectors or matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16de82e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A: tensor([1, 2, 3])\n",
      "TENSOR B tensor([4, 5, 6])\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "AFTER PERFORMING DOT PRODUCT: tensor(32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B\", b)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "dot_product = torch.matmul(a, b)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING DOT PRODUCT:\", dot_product, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb710074",
   "metadata": {},
   "source": [
    "* **Broadcasting**: The automatic expansion of smaller tensors to match the shape of larger tensors during arithmetic operations.\n",
    "    * Broadcasting allows operations between tensors with compatible shapes, even if they don't have the exact same dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1ada1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A: tensor([1, 2, 3])\n",
      "SHAPE: torch.Size([3])\n",
      "\n",
      "TENSOR B\n",
      "\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "\n",
      "SHAPE: torch.Size([3, 1])\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "TENSOR C:\n",
      "\n",
      " tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "SHAPE: torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([[1],\n",
    "                 [2],\n",
    "                 [3]])\n",
    "\n",
    "print(\"TENSOR A:\", a)\n",
    "print(\"SHAPE:\", a.shape)\n",
    "print(\"\\nTENSOR B\\n\\n\", b)\n",
    "print(\"\\nSHAPE:\", b.shape)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Apply broadcasting\n",
    "c = a + b\n",
    "\n",
    "print(\"\\nTENSOR C:\\n\\n\", c)\n",
    "print(\"\\nSHAPE:\", c.shape, \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2da9f",
   "metadata": {},
   "source": [
    "### 4.2 Logic Comparison\n",
    "Logical operations are powerful tools for data preparation and analysis. They allow us to create boolean masks to filter, select, or modify our data based on specific conditions we define.\n",
    "\n",
    "**comparison operators**: Element-wise comparisons (`>, ==, <`) that produce a boolean tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdb20fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPERATURES: tensor([20, 35, 19, 35, 42])\n",
      "--------------------------------------------------\n",
      "\n",
      "HOT (> 30 DEGREES): tensor([False,  True, False,  True,  True])\n",
      "COOL (<= 20 DEGREES): tensor([ True, False,  True, False, False])\n",
      "EXACTLY 35 DEGREES: tensor([False,  True, False,  True, False]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperatures = torch.tensor([20, 35, 19, 35, 42])\n",
    "print(\"TEMPERATURES:\", temperatures)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "### Comparison Operators (>, <, ==)\n",
    "\n",
    "# Use '>' (greater than) to find temperatures above 30\n",
    "is_hot = temperatures > 30\n",
    "\n",
    "# Use '<=' (less than or equal to) to find temperatures 20 or below\n",
    "is_cool = temperatures <= 20\n",
    "\n",
    "# Use '==' (equal to) to find temperatures exactly equal to 35\n",
    "is_35_deg = temperatures == 35\n",
    "\n",
    "print(\"\\nHOT (> 30 DEGREES):\", is_hot)\n",
    "print(\"COOL (<= 20 DEGREES):\", is_cool)\n",
    "print(\"EXACTLY 35 DEGREES:\", is_35_deg, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc23cc",
   "metadata": {},
   "source": [
    "* **Logical Operators**: Element-wise logical operations (`&` for **AND**, `|` for **OR**) on boolean tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4575d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS MORNING: tensor([ True, False, False,  True])\n",
      "IS RAINING: tensor([False, False,  True,  True])\n",
      "--------------------------------------------------\n",
      "\n",
      "MORNING & (AND) RAINING: tensor([False, False, False,  True])\n",
      "MORNING | (OR) RAINING: tensor([ True, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "is_morning = torch.tensor([True, False, False, True])\n",
    "is_raining = torch.tensor([False, False, True, True])\n",
    "print(\"IS MORNING:\", is_morning)\n",
    "print(\"IS RAINING:\", is_raining)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "### Logical Operators (&, |)\n",
    "\n",
    "# Use '&' (AND) to find when it's both morning and raining\n",
    "morning_raining = (is_morning & is_raining)\n",
    "\n",
    "# Use '|' (OR) to find when it's either morning or raining\n",
    "morning_or_raining = is_morning | is_raining\n",
    "\n",
    "print(\"\\nMORNING & (AND) RAINING:\", morning_raining)\n",
    "print(\"MORNING | (OR) RAINING:\", morning_or_raining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10327707",
   "metadata": {},
   "source": [
    "### 4.3 Statistics\n",
    "Calculating statistics like the mean or standard deviation can be useful for understanding our dataset or for implementing certain types of normalization during the data preparation phase.\n",
    "\n",
    "`torch.mean()`, Calculates the mean of all elements in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9cd912fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: tensor([10., 20., 30., 40., 50.])\n",
      "---------------------------------------------\n",
      "\n",
      "CALCULATED MEAN: tensor(30.) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([10.0, 20.0, 30.0, 40.0, 50.0])\n",
    "print(\"DATA:\", data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Calculate the mean\n",
    "data_mean = data.mean()\n",
    "\n",
    "print(\"\\nCALCULATED MEAN:\", data_mean, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb0ebeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: tensor([10., 20., 30., 40., 50.])\n",
      "---------------------------------------------\n",
      "\n",
      "CALCULATED STD: tensor(15.8114) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate std\n",
    "print(\"DATA:\", data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Calculate the std\n",
    "data_std = data.std()\n",
    "\n",
    "print(\"\\nCALCULATED STD:\", data_std, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17972b5f",
   "metadata": {},
   "source": [
    "### 4.4 Data Types\n",
    "Just as important as a tensor's shape is its data type. Neural networks typically perform their calculations using 32-bit floating point numbers (float32). Providing data of the wrong type, such as an integer, can lead to runtime errors or unexpected behavior during training. It is a good practice to ensure our tensors have the correct data type for our model.\n",
    "\n",
    "**Type Casting (`.int`, etc.)**: Converts a tensor from one data type to another (e.g., from float to integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ef69e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: tensor([10., 20., 30., 40., 50.])\n",
      "DATA TYPE: torch.float32\n",
      "---------------------------------------------\n",
      "\n",
      "CASTED DATA: tensor([10, 20, 30, 40, 50], dtype=torch.int32)\n",
      "CASTED DATA TYPE torch.int32\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA:\", data)\n",
    "print(\"DATA TYPE:\", data.dtype)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Cast to the tensor to a int type\n",
    "int_tensor = data.int()\n",
    "\n",
    "print(\"\\nCASTED DATA:\", int_tensor)\n",
    "print(\"CASTED DATA TYPE\", int_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843d137",
   "metadata": {},
   "source": [
    "## Application\n",
    "### Analyzing Monthly Sales Data\n",
    "We're a data analyst at an e-commerce company. We've been given a tensor representing the monthly sales of three different products over a period of four months. Our task is to extract meaningful insights from this data.\n",
    "\n",
    "The tensor `sales_data` is structured as follows:\n",
    "\n",
    "* **Rows** represent the **products** (Product A, Product B, Product C).\n",
    "\n",
    "* **Columns** represent the **months** (Jan, Feb, Mar, Apr).\n",
    "\n",
    "**Our goals are**:\n",
    "\n",
    "1. Calculate the total sales for **Product B** (the second row).\n",
    "2. Identify which months had sales **greater than 130** for **Product C** (the third row) using boolean masking.\n",
    "3. Extract the sales data for all products for the months of **Feb and Mar** (the middle two columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a126ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL SALES DATA:\n",
      "\n",
      " tensor([[100., 120., 130., 110.],\n",
      "        [ 90.,  95., 105., 125.],\n",
      "        [140., 115., 120., 150.]])\n",
      "---------------------------------------------\n",
      "\n",
      "Total Sales for Product B:                    tensor(415.)\n",
      "\n",
      "Months with >130 Sales for Product C (Mask):  tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [ True, False, False,  True]])\n",
      "\n",
      "Sales for Feb & Mar:\n",
      "\n",
      " tensor([[120., 130.],\n",
      "        [ 95., 105.],\n",
      "        [115., 120.]])\n"
     ]
    }
   ],
   "source": [
    "# Sales data for 3 products over 4 months\n",
    "sales_data = torch.tensor([[100, 120, 130, 110],   # Product A\n",
    "                           [ 90,  95, 105, 125],   # Product B\n",
    "                           [140, 115, 120, 150]    # Product C\n",
    "                          ], dtype=torch.float32)\n",
    "\n",
    "print(\"ORIGINAL SALES DATA:\\n\\n\", sales_data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "total_sales_product_b = sales_data[1].sum()\n",
    "\n",
    "# months where sales for Product C were > 130.\n",
    "high_sales_mask_product_c = sales_data > 130\n",
    "\n",
    "# 3. Get sales for Feb and Mar for all products.\n",
    "sales_feb_mar = sales_data[:3, 1:3]\n",
    "\n",
    "print(\"\\nTotal Sales for Product B:                   \", total_sales_product_b)\n",
    "print(\"\\nMonths with >130 Sales for Product C (Mask): \", high_sales_mask_product_c)\n",
    "print(\"\\nSales for Feb & Mar:\\n\\n\", sales_feb_mar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5285781",
   "metadata": {},
   "source": [
    "### Image Batch Transformation\n",
    "We're  working on a computer vision model and have a batch of 4 grayscale images, each of size 3x3 pixels. The data is currently in a tensor with the shape `[4, 3, 3]`, which represents `[batch_size, height, width]`.\n",
    "\n",
    "For processing with certain deep learning frameworks, we need to transform this data into the `[batch_size, channels, height, width]` format. Since the images are grayscale, **We'll need to**:\n",
    "\n",
    "1. Add a new dimension of size 1 at index 1 to represent the color channel.\n",
    "2. After adding the channel, we realize the model expects the shape `[batch_size, height, width, channels]`. Transpose the tensor to swap the channel dimension with the last dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f09047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL BATCH SHAPE: torch.Size([4, 3, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "SHAPE AFTER UNSQUEEZE: torch.Size([4, 1, 3, 3])\n",
      "SHAPE AFTER TRANSPOSE: torch.Size([4, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# A batch of 4 grayscale images, each 3x3\n",
    "image_batch = torch.rand(4, 3, 3)\n",
    "\n",
    "print(\"ORIGINAL BATCH SHAPE:\", image_batch.shape)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# 1. Add a channel dimension at index 1.\n",
    "image_batch_with_channel = image_batch.unsqueeze(1)\n",
    "\n",
    "# 2. Transpose the tensor to move the channel dimension to the end.\n",
    "# Swap dimension 1 (channels) with dimension 3 (the last one).\n",
    "image_batch_transposed = image_batch_with_channel.transpose(1, 3)\n",
    "\n",
    "\n",
    "print(\"\\nSHAPE AFTER UNSQUEEZE:\", image_batch_with_channel.shape)\n",
    "print(\"SHAPE AFTER TRANSPOSE:\", image_batch_transposed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "63cfd7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9843, 0.2384, 0.7642],\n",
       "         [0.6845, 0.6382, 0.1560],\n",
       "         [0.7144, 0.3712, 0.4692]],\n",
       "\n",
       "        [[0.6015, 0.3743, 0.5540],\n",
       "         [0.7178, 0.5430, 0.2579],\n",
       "         [0.7328, 0.2197, 0.8020]],\n",
       "\n",
       "        [[0.1134, 0.0218, 0.4536],\n",
       "         [0.6403, 0.4022, 0.7354],\n",
       "         [0.9324, 0.0285, 0.3136]],\n",
       "\n",
       "        [[0.7164, 0.4929, 0.8112],\n",
       "         [0.3540, 0.0085, 0.6160],\n",
       "         [0.0157, 0.4787, 0.3039]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84545585",
   "metadata": {},
   "source": [
    "### Combining and Weighting Sensor Data\n",
    "We're building an environment monitoring system that uses two sensors: one for temperature and one for humidity. We receive data from these sensors as two separate 1D tensors.\n",
    "\n",
    "**Our task is to**:\n",
    "\n",
    "1. **Concatenate** the two tensors into a single `2x5` tensor, where the first row is temperature data and the second is humidity data.\n",
    "2. Create a `weights` tensor `torch.tensor([0.6, 0.4])`.\n",
    "3. Use **broadcasting and element-wise multiplication** to apply these weights to the combined sensor data. The temperature data should be multiplied by 0.6 and the humidity data by 0.4.\n",
    "4. Finally, calculate the **weighted average** for each time step by **summing** the weighted values along `dim=0` and **dividing** by the sum of the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6592d4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPERATURE DATA:  tensor([22.5000, 23.1000, 21.9000, 22.8000, 23.5000])\n",
      "HUMIDITY DATA:     tensor([55.2000, 56.4000, 54.8000, 57.1000, 56.8000])\n",
      "---------------------------------------------\n",
      "\n",
      "COMBINED DATA (2x5):\n",
      "\n",
      " tensor([[22.5000, 23.1000, 21.9000, 22.8000, 23.5000],\n",
      "        [55.2000, 56.4000, 54.8000, 57.1000, 56.8000]])\n",
      "\n",
      "WEIGHTED DATA:\n",
      "\n",
      " tensor([[13.5000, 13.8600, 13.1400, 13.6800, 14.1000],\n",
      "        [22.0800, 22.5600, 21.9200, 22.8400, 22.7200]])\n",
      "\n",
      "WEIGHTED AVERAGE: tensor([35.5800, 36.4200, 35.0600, 36.5200, 36.8200])\n"
     ]
    }
   ],
   "source": [
    "# Sensor readings (5 time steps)\n",
    "temperature = torch.tensor([22.5, 23.1, 21.9, 22.8, 23.5])\n",
    "humidity = torch.tensor([55.2, 56.4, 54.8, 57.1, 56.8])\n",
    "\n",
    "print(\"TEMPERATURE DATA: \", temperature)\n",
    "print(\"HUMIDITY DATA:    \", humidity)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "#  1. Concatenate the two tensors.\n",
    "# Note:  unsqueeze them first to stack them vertically.\n",
    "combined_data = torch.cat((torch.unsqueeze(temperature, 0), torch.unsqueeze(humidity, 0)))\n",
    "\n",
    "# 2. Create the weights tensor.\n",
    "weights = torch.tensor([0.6, 0.4])\n",
    "\n",
    "# 3. Apply weights using broadcasting.\n",
    "# reshape weights to [2, 1] to broadcast across columns.\n",
    "weighted_data = combined_data * weights.reshape(2, 1)\n",
    "\n",
    "# 4. Calculate the weighted average for each time step.\n",
    "#    (A true average = weighted sum / sum of weights)\n",
    "weighted_sum = torch.sum(weighted_data, dim=0)\n",
    "weighted_average = weighted_sum / torch.sum(weights)\n",
    "\n",
    "print(\"\\nCOMBINED DATA (2x5):\\n\\n\", combined_data)\n",
    "print(\"\\nWEIGHTED DATA:\\n\\n\", weighted_data)\n",
    "print(\"\\nWEIGHTED AVERAGE:\", weighted_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ed208",
   "metadata": {},
   "source": [
    "### Feature Engineering for Taxi Fares\n",
    "We are working with a dataset of taxi trips. We have a tensor, `trip_data`, where each row is a trip and the columns represent **[distance (km), hour_of_day (24h)]**.\n",
    "\n",
    "**Our goal** is to engineer a new binary feature called `is_rush_hour_long_trip`. This feature should be `True` (or `1`) only if a trip meets **both** of the following criteria:\n",
    "\n",
    "* It's a **long trip** (distance > 10 km).\n",
    "* It occurs during a **rush hour** (8-10 AM or 5-7 PM, i.e., `[8, 10)` or `[17, 19)`).\n",
    "\n",
    "To achieve this, we will need to:\n",
    "\n",
    "1. **Slice** the `trip_data` tensor to isolate the `distance` and `hour` columns.\n",
    "2. Use **logical and comparison operators** to create boolean masks for each condition (long trip, morning rush, evening rush).\n",
    "3. Combine these masks to create the final `is_rush_hour_long_trip` feature.\n",
    "4. **Reshape** this new 1D feature tensor into a 2D column vector and convert its data type to float so it can be combined with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a1ec97b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TRIP DATA (Distance, Hour):\n",
      "\n",
      " tensor([[ 5.3000,  7.0000],\n",
      "        [12.1000,  9.0000],\n",
      "        [15.5000, 13.0000],\n",
      "        [ 6.7000, 18.0000],\n",
      "        [ 2.4000, 20.0000],\n",
      "        [11.8000, 17.0000],\n",
      "        [ 9.0000,  9.0000],\n",
      "        [14.2000,  8.0000]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "'IS RUSH HOUR LONG TRIP' MASK:  tensor([False,  True, False, False, False,  True, False,  True])\n",
      "\n",
      "NEW FEATURE COLUMN (Reshaped):\n",
      "\n",
      " tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "\n",
      "ENHANCED DATA (with new feature at the end):\n",
      "\n",
      " tensor([[ 5.3000,  7.0000,  0.0000],\n",
      "        [12.1000,  9.0000,  1.0000],\n",
      "        [15.5000, 13.0000,  0.0000],\n",
      "        [ 6.7000, 18.0000,  0.0000],\n",
      "        [ 2.4000, 20.0000,  0.0000],\n",
      "        [11.8000, 17.0000,  1.0000],\n",
      "        [ 9.0000,  9.0000,  0.0000],\n",
      "        [14.2000,  8.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Data for 8 taxi trips: [distance, hour_of_day]\n",
    "trip_data = torch.tensor([\n",
    "    [5.3, 7],   # Not rush hour, not long\n",
    "    [12.1, 9],  # Morning rush, long trip -> RUSH HOUR LONG\n",
    "    [15.5, 13], # Not rush hour, long trip\n",
    "    [6.7, 18],  # Evening rush, not long\n",
    "    [2.4, 20],  # Not rush hour, not long\n",
    "    [11.8, 17], # Evening rush, long trip -> RUSH HOUR LONG\n",
    "    [9.0, 9],   # Morning rush, not long\n",
    "    [14.2, 8]   # Morning rush, long trip -> RUSH HOUR LONG\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(\"ORIGINAL TRIP DATA (Distance, Hour):\\n\\n\", trip_data)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "\n",
    "# 1. Slice the main tensor to get 1D tensors for each feature.\n",
    "distances = trip_data[:, 0]\n",
    "hours = trip_data[:, 1]\n",
    "\n",
    "# 2. Create boolean masks for each condition.\n",
    "is_long_trip = distances > 10\n",
    "is_morning_rush = (hours >= 8) & (hours < 10) \n",
    "is_evening_rush = (hours >=17) & (hours < 19)\n",
    "\n",
    "\n",
    "# 3. Combine masks to identify rush hour long trips.\n",
    "# A trip is a rush hour long trip if it's (a morning OR evening rush) AND a long trip.\n",
    "is_rush_hour_long_trip_mask = (is_morning_rush | is_evening_rush) & is_long_trip\n",
    "\n",
    "# 4. Reshape the new feature into a column vector and cast to float.\n",
    "new_feature_col = is_rush_hour_long_trip_mask.float().unsqueeze(1)\n",
    "# new_feature_col = \n",
    "\n",
    "\n",
    "print(\"\\n'IS RUSH HOUR LONG TRIP' MASK: \", is_rush_hour_long_trip_mask)\n",
    "print(\"\\nNEW FEATURE COLUMN (Reshaped):\\n\\n\", new_feature_col)\n",
    "\n",
    "# You can now concatenate this new feature to the original data\n",
    "enhanced_trip_data = torch.cat((trip_data, new_feature_col), dim=1)\n",
    "print(\"\\nENHANCED DATA (with new feature at the end):\\n\\n\", enhanced_trip_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca64a1d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
